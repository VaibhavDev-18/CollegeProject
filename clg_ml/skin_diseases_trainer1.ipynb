{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "813bc3e1-6619-4df0-928d-1a26a0f52ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input, Multiply, Reshape, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5fa43fb-8988-4974-a3c2-f6e216464ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CONFIG ==========\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_PHASE_1 = 10\n",
    "EPOCHS_PHASE_2 = 30\n",
    "LEARNING_RATE_PHASE_1 = 1e-4\n",
    "LEARNING_RATE_PHASE_2 = 1e-5\n",
    "UNFREEZE_LAYERS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d41f1a64-d824-49dc-a9d1-3f47c5d87edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/k/ml/clg_ml/domain_specific_classification\"\n",
    "train_dir = os.path.join(BASE_DIR, \"train/skin_diseases\")\n",
    "val_dir = os.path.join(BASE_DIR, \"val/skin_diseases\")\n",
    "test_dir = os.path.join(BASE_DIR, \"test/skin_diseases\")\n",
    "MODEL_PATH = \"skin_diseases_model.h5\"\n",
    "google_images_dir = '/mnt/k/ml/clg_ml/imgs_from_google/domainSpecificClassifier/skin_diseases/'\n",
    "class_labels = ['benign keratosis like lesion', 'eczema']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fc64120-19b5-4fbd-aebc-7b0caf56853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== SE BLOCK ==========\n",
    "def squeeze_excite_block(input_tensor, ratio=16):\n",
    "    '''Create a squeeze and excitation block'''\n",
    "    filters = input_tensor.shape[-1]\n",
    "    se = tf.keras.layers.GlobalAveragePooling2D()(input_tensor)\n",
    "    se = Reshape((1, 1, filters))(se)\n",
    "    se = Dense(filters // ratio, activation='relu', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
    "    x = Multiply()([input_tensor, se])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "285095e8-ae72-4024-87bf-d4bcba2a1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== DATA ==========\n",
    "def create_generators():\n",
    "    train_gen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    ).flow_from_directory(train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=True)\n",
    "\n",
    "    val_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(val_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "    test_gen = ImageDataGenerator(rescale=1./255).flow_from_directory(test_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical', shuffle=False)\n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eec0654-c236-4bb4-8cde-e9afb2458019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== MODEL ==========\n",
    "def build_model(num_classes):\n",
    "    base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base.trainable = False  # Phase 1: freeze backbone\n",
    "\n",
    "    x = base.output\n",
    "    x = squeeze_excite_block(x)  # <-- Attention block here\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs=base.input, outputs=output), base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fe50af1-0cab-4199-ac7c-4da3a7182864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== TRAINING ==========\n",
    "def train_model():\n",
    "    train_gen, val_gen, test_gen = create_generators()\n",
    "    model, base_model = build_model(num_classes=2)\n",
    "\n",
    "    # Phase 1: Train top classifier\n",
    "    print(\"🔹 Phase 1: Training classifier head...\")\n",
    "    model.compile(optimizer=Adam(LEARNING_RATE_PHASE_1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(patience=3, factor=0.2, min_lr=1e-6),\n",
    "        ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='val_accuracy', verbose=1)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_PHASE_1, callbacks=callbacks)\n",
    "\n",
    "    # Phase 2: Fine-tuning last N layers\n",
    "    print(\"🔹 Phase 2: Fine-tuning base model...\")\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-UNFREEZE_LAYERS]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model.compile(optimizer=Adam(LEARNING_RATE_PHASE_2), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.fit(train_gen, validation_data=val_gen, epochs=EPOCHS_PHASE_2, callbacks=callbacks)\n",
    "\n",
    "    # Load best weights before evaluation\n",
    "    print(\"📦 Loading best model weights...\")\n",
    "    model.load_weights(MODEL_PATH)\n",
    "\n",
    "    # Final evaluation\n",
    "    evaluate_model(model, test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "015c7b4c-2a8a-4df5-805f-9ddbd9813841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_gen):\n",
    "    print(\"📊 Evaluating model on test set...\")\n",
    "    test_gen.reset()\n",
    "    \n",
    "    y_true = test_gen.classes\n",
    "    class_labels = list(test_gen.class_indices.keys())\n",
    "    \n",
    "    # Predict probabilities\n",
    "    y_pred_probs = model.predict(test_gen, verbose=1)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    print(f\"\\n✅ Test Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"📄 Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_labels))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"🔁 Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48db1f2b-832b-4ae4-b3d1-3c9637c59907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    img_array = img_array / 255.0  # Normalize\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "684bfe23-3eaa-4a24-a527-f8e4d4893936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_images():\n",
    "    model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    print(f\"🔍 Loaded model from: {MODEL_PATH}\")\n",
    "\n",
    "    image_files = [f for f in os.listdir(google_images_dir)\n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp'))]\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"❌ No images found in directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n🧪 Classifying {len(image_files)} images from: {google_images_dir}\\n\")\n",
    "\n",
    "    for img_file in sorted(image_files):\n",
    "        img_path = os.path.join(google_images_dir, img_file)\n",
    "        img_array = preprocess_image(img_path)\n",
    "\n",
    "        preds = model.predict(img_array, verbose=0)\n",
    "        pred_index = np.argmax(preds[0])\n",
    "        confidence = preds[0][pred_index] * 100\n",
    "\n",
    "        predicted_class = class_labels[pred_index]\n",
    "        print(f\"{img_file} → Predicted: {predicted_class} ({confidence:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f462d5a-d4ce-421d-93d8-099b8344c44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3028 images belonging to 2 classes.\n",
      "Found 364 images belonging to 2 classes.\n",
      "Found 360 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760069480.907348     799 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3618 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Phase 1: Training classifier head...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/k/ml/clg_ml/venv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 09:41:34.659192: I external/local_xla/xla/service/service.cc:163] XLA service 0x7ff544001820 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-10 09:41:34.659236: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-10-10 09:41:35.178798: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-10 09:41:37.877966: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
      "2025-10-10 09:41:37.189596: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:41:37.189682: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:41:37.189741: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:41:37.189750: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:41:38.582122: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11943', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2025-10-10 09:41:38.891460: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13395', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2025-10-10 09:41:39.931451: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_13411', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "I0000 00:00:1760069523.298972    1351 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/95\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 513ms/step - accuracy: 0.4425 - loss: 1.3800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 09:42:12.074235: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:42:12.074311: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:42:14.043542: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_11943', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794ms/step - accuracy: 0.6766 - loss: 0.7233"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 09:43:22.728631: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-10 09:43:23.114950: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3399', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n",
      "2025-10-10 09:43:23.478409: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3406', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "2025-10-10 09:43:36.185512: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3399', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_accuracy improved from None to 0.99176, saving model to skin_diseases_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 1s/step - accuracy: 0.8382 - loss: 0.3862 - val_accuracy: 0.9918 - val_loss: 0.2119 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.9739 - loss: 0.0939\n",
      "Epoch 2: val_accuracy improved from 0.99176 to 0.99725, saving model to skin_diseases_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 421ms/step - accuracy: 0.9779 - loss: 0.0804 - val_accuracy: 0.9973 - val_loss: 0.0790 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410ms/step - accuracy: 0.9800 - loss: 0.0619\n",
      "Epoch 3: val_accuracy did not improve from 0.99725\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 454ms/step - accuracy: 0.9855 - loss: 0.0507 - val_accuracy: 0.9973 - val_loss: 0.0364 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.9897 - loss: 0.0404\n",
      "Epoch 4: val_accuracy did not improve from 0.99725\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 431ms/step - accuracy: 0.9891 - loss: 0.0384 - val_accuracy: 0.9973 - val_loss: 0.0164 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.9940 - loss: 0.0262\n",
      "Epoch 5: val_accuracy improved from 0.99725 to 1.00000, saving model to skin_diseases_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 434ms/step - accuracy: 0.9937 - loss: 0.0259 - val_accuracy: 1.0000 - val_loss: 0.0108 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 601ms/step - accuracy: 0.9923 - loss: 0.0283\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 660ms/step - accuracy: 0.9914 - loss: 0.0287 - val_accuracy: 1.0000 - val_loss: 0.0053 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.9923 - loss: 0.0298\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 440ms/step - accuracy: 0.9941 - loss: 0.0224 - val_accuracy: 1.0000 - val_loss: 0.0045 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.9938 - loss: 0.0187\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 393ms/step - accuracy: 0.9934 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0023 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.9952 - loss: 0.0190\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 409ms/step - accuracy: 0.9964 - loss: 0.0152 - val_accuracy: 1.0000 - val_loss: 0.0013 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9973 - loss: 0.0118\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 404ms/step - accuracy: 0.9967 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 0.0012 - learning_rate: 1.0000e-04\n",
      "🔹 Phase 2: Fine-tuning base model...\n",
      "Epoch 1/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 514ms/step - accuracy: 0.9931 - loss: 0.0202\n",
      "Epoch 1: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 687ms/step - accuracy: 0.9937 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0011 - learning_rate: 1.0000e-05\n",
      "Epoch 2/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9917 - loss: 0.0211\n",
      "Epoch 2: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 401ms/step - accuracy: 0.9931 - loss: 0.0204 - val_accuracy: 1.0000 - val_loss: 7.7525e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 3/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.9952 - loss: 0.0189\n",
      "Epoch 3: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 406ms/step - accuracy: 0.9934 - loss: 0.0199 - val_accuracy: 1.0000 - val_loss: 6.5829e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 4/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435ms/step - accuracy: 0.9934 - loss: 0.0214\n",
      "Epoch 4: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 473ms/step - accuracy: 0.9921 - loss: 0.0206 - val_accuracy: 1.0000 - val_loss: 6.0856e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 5/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.9946 - loss: 0.0119\n",
      "Epoch 5: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 445ms/step - accuracy: 0.9954 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 5.0344e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 6/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.9966 - loss: 0.0110\n",
      "Epoch 6: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 405ms/step - accuracy: 0.9957 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 4.8933e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 7/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.9970 - loss: 0.0116\n",
      "Epoch 7: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 432ms/step - accuracy: 0.9964 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 4.1816e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 8/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9969 - loss: 0.0125\n",
      "Epoch 8: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 397ms/step - accuracy: 0.9960 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 4.0920e-04 - learning_rate: 1.0000e-05\n",
      "Epoch 9/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.9956 - loss: 0.0120\n",
      "Epoch 9: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 415ms/step - accuracy: 0.9950 - loss: 0.0134 - val_accuracy: 1.0000 - val_loss: 4.0222e-04 - learning_rate: 2.0000e-06\n",
      "Epoch 10/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9953 - loss: 0.0111\n",
      "Epoch 10: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 396ms/step - accuracy: 0.9950 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 3.9594e-04 - learning_rate: 2.0000e-06\n",
      "Epoch 11/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.9971 - loss: 0.0103\n",
      "Epoch 11: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 406ms/step - accuracy: 0.9967 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 3.8305e-04 - learning_rate: 2.0000e-06\n",
      "Epoch 12/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371ms/step - accuracy: 0.9962 - loss: 0.0139\n",
      "Epoch 12: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 405ms/step - accuracy: 0.9960 - loss: 0.0124 - val_accuracy: 1.0000 - val_loss: 3.6776e-04 - learning_rate: 2.0000e-06\n",
      "Epoch 13/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step - accuracy: 0.9966 - loss: 0.0105\n",
      "Epoch 13: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 399ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 1.0000 - val_loss: 3.6412e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 14/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9949 - loss: 0.0204\n",
      "Epoch 14: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 402ms/step - accuracy: 0.9967 - loss: 0.0157 - val_accuracy: 1.0000 - val_loss: 3.6654e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 15/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369ms/step - accuracy: 0.9936 - loss: 0.0133\n",
      "Epoch 15: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 404ms/step - accuracy: 0.9957 - loss: 0.0120 - val_accuracy: 1.0000 - val_loss: 3.5740e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 16/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9967 - loss: 0.0098\n",
      "Epoch 16: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 414ms/step - accuracy: 0.9974 - loss: 0.0090 - val_accuracy: 1.0000 - val_loss: 3.5243e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 17/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446ms/step - accuracy: 0.9974 - loss: 0.0106\n",
      "Epoch 17: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 482ms/step - accuracy: 0.9960 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 3.4976e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 18/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 347ms/step - accuracy: 0.9962 - loss: 0.0132\n",
      "Epoch 18: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 381ms/step - accuracy: 0.9957 - loss: 0.0122 - val_accuracy: 1.0000 - val_loss: 3.4469e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 19/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9955 - loss: 0.0156\n",
      "Epoch 19: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 395ms/step - accuracy: 0.9977 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 3.3845e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 20/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.9981 - loss: 0.0086\n",
      "Epoch 20: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 425ms/step - accuracy: 0.9974 - loss: 0.0105 - val_accuracy: 1.0000 - val_loss: 3.3857e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 21/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.9959 - loss: 0.0120\n",
      "Epoch 21: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 410ms/step - accuracy: 0.9967 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 3.4446e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 22/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.9933 - loss: 0.0219\n",
      "Epoch 22: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 389ms/step - accuracy: 0.9954 - loss: 0.0151 - val_accuracy: 1.0000 - val_loss: 3.3447e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 23/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step - accuracy: 0.9952 - loss: 0.0113\n",
      "Epoch 23: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 399ms/step - accuracy: 0.9957 - loss: 0.0128 - val_accuracy: 1.0000 - val_loss: 3.3228e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 24/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 354ms/step - accuracy: 0.9978 - loss: 0.0087\n",
      "Epoch 24: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 385ms/step - accuracy: 0.9967 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 3.2077e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 25/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 355ms/step - accuracy: 0.9958 - loss: 0.0110\n",
      "Epoch 25: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 386ms/step - accuracy: 0.9964 - loss: 0.0102 - val_accuracy: 1.0000 - val_loss: 3.2365e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 26/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 353ms/step - accuracy: 0.9951 - loss: 0.0140\n",
      "Epoch 26: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 385ms/step - accuracy: 0.9967 - loss: 0.0116 - val_accuracy: 1.0000 - val_loss: 3.1808e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 27/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362ms/step - accuracy: 0.9975 - loss: 0.0092\n",
      "Epoch 27: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 396ms/step - accuracy: 0.9964 - loss: 0.0110 - val_accuracy: 1.0000 - val_loss: 3.0948e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 28/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359ms/step - accuracy: 0.9954 - loss: 0.0172\n",
      "Epoch 28: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 391ms/step - accuracy: 0.9967 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 3.1158e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 29/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370ms/step - accuracy: 0.9941 - loss: 0.0170\n",
      "Epoch 29: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 403ms/step - accuracy: 0.9954 - loss: 0.0138 - val_accuracy: 1.0000 - val_loss: 3.0882e-04 - learning_rate: 1.0000e-06\n",
      "Epoch 30/30\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361ms/step - accuracy: 0.9972 - loss: 0.0121\n",
      "Epoch 30: val_accuracy did not improve from 1.00000\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 393ms/step - accuracy: 0.9983 - loss: 0.0087 - val_accuracy: 1.0000 - val_loss: 3.0124e-04 - learning_rate: 1.0000e-06\n",
      "📦 Loading best model weights...\n",
      "📊 Evaluating model on test set...\n",
      "\u001b[1m11/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 230ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 10:10:49.362757: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_3344', 8 bytes spill stores, 8 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 2s/step\n",
      "\n",
      "✅ Test Accuracy: 0.9889\n",
      "\n",
      "📄 Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "benign_keratosis       0.98      1.00      0.99       204\n",
      "          eczema       1.00      0.97      0.99       156\n",
      "\n",
      "        accuracy                           0.99       360\n",
      "       macro avg       0.99      0.99      0.99       360\n",
      "    weighted avg       0.99      0.99      0.99       360\n",
      "\n",
      "🔁 Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdf08d03-ccac-48ba-a24b-ee7c8c1659df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Loaded model from: skin_diseases_model.h5\n",
      "\n",
      "🧪 Classifying 12 images from: /mnt/k/ml/clg_ml/imgs_from_google/domainSpecificClassifier/skin_diseases/\n",
      "\n",
      "be_ke_le.jpeg → Predicted: benign keratosis like lesion (71.15%)\n",
      "be_ke_le2.jpg → Predicted: eczema (82.63%)\n",
      "be_ke_le3.jpg → Predicted: benign keratosis like lesion (72.98%)\n",
      "be_ke_le4.jpg → Predicted: benign keratosis like lesion (100.00%)\n",
      "be_ke_le5.jpg → Predicted: benign keratosis like lesion (99.91%)\n",
      "be_ke_le6.jpg → Predicted: benign keratosis like lesion (99.99%)\n",
      "be_ke_le7.webp → Predicted: eczema (99.32%)\n",
      "be_ke_le8.jpg → Predicted: benign keratosis like lesion (90.31%)\n",
      "ecz9 (157).jpg → Predicted: eczema (99.99%)\n",
      "ecz9 (158).jpg → Predicted: eczema (99.64%)\n",
      "ecz9 (159).jpg → Predicted: eczema (99.92%)\n",
      "ecz9 (160).jpg → Predicted: eczema (99.85%)\n"
     ]
    }
   ],
   "source": [
    "classify_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689236cc-66f3-47e9-a5f2-cb853460017b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b53e3f-1a19-4256-bb91-c3f00af52303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce24a71a-27b9-49b5-a340-ca946d78f401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51f7e9-e510-490d-b377-be6cb1fbd9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f115e04-87fa-4d5e-8bb2-f0553f55f612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe7726-eb1a-4f39-b3ee-2bb4eacb336a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
