{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16b0564d-b1e1-4869-a925-476048a28704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b3381b4-f57f-4441-a14c-28242c225437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== CONFIGURATION ====================\n",
    "IMG_HEIGHT, IMG_WIDTH = 224, 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "INITIAL_LR = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dcf720b0-2edb-47d6-9bbf-57e81878e57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = '/mnt/k/ml/clg_ml/domain_classification/train'\n",
    "val_dir = '/mnt/k/ml/clg_ml/domain_classification/val'\n",
    "test_dir = '/mnt/k/ml/clg_ml/domain_classification/test'\n",
    "google_images_dir = '/mnt/k/ml/clg_ml/imgs_from_google/domainClassifier/'\n",
    "MODEL_PATH = 'domain_classifier_best.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e52f5d9-c191-491e-ab63-a0585a85801c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== DATA PREPARATION ====================\n",
    "def create_data_generators():\n",
    "    # Training data generator with augmentation\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Validation and test data generator (only rescaling)\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    # Create generators\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_generator = val_test_datagen.flow_from_directory(\n",
    "        val_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    test_generator = val_test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator, test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd77a0af-6167-45a0-aea1-3ffa78e54441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MODEL ARCHITECTURE ====================\n",
    "def build_domain_classifier():\n",
    "    # Load pre-trained DenseNet121\n",
    "    base_model = DenseNet121(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze base model initially\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Add custom head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    predictions = Dense(2, activation='softmax', name='domain_output')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model, base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "297d7b69-d3e5-4bb1-b373-b4475b751c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== TRAINING STRATEGY ====================\n",
    "def get_callbacks():\n",
    "    \"\"\"Define training callbacks\"\"\"\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        MODEL_PATH,\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return [checkpoint, early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90455866-b63b-48de-9766-0c29db9425e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_domain_classifier():\n",
    "    # Create data generators\n",
    "    train_gen, val_gen, test_gen = create_data_generators()\n",
    "    \n",
    "    # Build model\n",
    "    model, base_model = build_domain_classifier()\n",
    "    \n",
    "    # Phase 1: Train only the head\n",
    "    print(\"Phase 1: Training classifier head...\")\n",
    "    model.compile(\n",
    "        optimizer=Adam(INITIAL_LR),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history_head = model.fit(\n",
    "        train_gen,\n",
    "        epochs=10,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=get_callbacks(),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Phase 2: Fine-tune deeper layers\n",
    "    print(\"Phase 2: Fine-tuning deeper layers...\")\n",
    "    \n",
    "    # Unfreeze last 50 layers of base model\n",
    "    base_model.trainable = True\n",
    "    for layer in base_model.layers[:-50]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(INITIAL_LR/10),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    history_full = model.fit(\n",
    "        train_gen,\n",
    "        epochs=EPOCHS,\n",
    "        initial_epoch=history_head.epoch[-1] + 1,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=get_callbacks(),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    return model, train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39e39cd0-3558-4466-b0bd-6b6eac189752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback_loop_retraining(\n",
    "    retrain_dir=os.path.join(os.path.dirname(google_images_dir), 'retrain'),\n",
    "    model_path=MODEL_PATH,\n",
    "    min_images=50,\n",
    "    epochs=10,\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=32\n",
    "):\n",
    "    import glob\n",
    "\n",
    "    # Count images in retrain folders\n",
    "    oral_images = glob.glob(os.path.join(retrain_dir, 'oral_disorder', '*'))\n",
    "    skin_images = glob.glob(os.path.join(retrain_dir, 'skin_diseases', '*'))\n",
    "\n",
    "    total_images = len(oral_images) + len(skin_images)\n",
    "    print(f\"üîÅ Feedback loop check: Found {total_images} images in retrain folder.\")\n",
    "\n",
    "    if total_images < min_images:\n",
    "        print(f\"‚è≥ Not enough data to retrain. Need {min_images}, have {total_images}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nüöÄ Triggering fine-tuning using {total_images} new images...\")\n",
    "\n",
    "    # Load the best model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "    # Unfreeze last few layers for fine-tuning\n",
    "    if hasattr(model, 'layers'):\n",
    "        base_model = model.layers[0]  # assuming base model is first\n",
    "        if hasattr(base_model, 'trainable'):\n",
    "            base_model.trainable = True\n",
    "            for layer in base_model.layers[:-30]:  # Unfreeze last 30 layers\n",
    "                layer.trainable = False\n",
    "            print(\"‚úÖ Last 30 layers of base model unfrozen for fine-tuning.\")\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Create generator for retrain data\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.1)\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        retrain_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_directory(\n",
    "        retrain_dir,\n",
    "        target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Retrain\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=epochs,\n",
    "        callbacks=get_callbacks(),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Save the updated model\n",
    "    model.save(model_path)\n",
    "    print(f\"üíæ Model re-trained and saved to: {model_path}\")\n",
    "\n",
    "    # Optional: Clear retrain folder after training\n",
    "    for folder in ['oral_disorder', 'skin_diseases']:\n",
    "        folder_path = os.path.join(retrain_dir, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            os.remove(os.path.join(folder_path, file))\n",
    "    print(\"üßπ Cleared retrain folder after training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b6f0548-4c7e-4e9e-bb67-97b456db4a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== EVALUATION ====================\n",
    "def evaluate_model(model, test_generator):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    \n",
    "    # Get true labels and predictions\n",
    "    test_generator.reset()\n",
    "    y_true = test_generator.classes\n",
    "    y_pred_probs = model.predict(test_generator)\n",
    "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
    "    \n",
    "    # Classification report\n",
    "    class_names = list(test_generator.class_indices.keys())\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLASSIFICATION REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(\"\\nCONFUSION MATRIX:\")\n",
    "    print(cm)\n",
    "    \n",
    "    # Overall accuracy\n",
    "    test_accuracy = np.sum(y_pred == y_true) / len(y_true)\n",
    "    print(f\"\\nOverall Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return test_accuracy, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f8414bb-b834-4771-8775-387203a41478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_google_images(model_path, google_images_dir, confidence_threshold=0.8):\n",
    "    # Load model\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    # Class names(must match subfolder names exactly)\n",
    "    class_names = ['oral_disorder', 'skin_diseases']\n",
    "    # Files to process\n",
    "    image_files = [f for f in os.listdir(google_images_dir)\n",
    "                   if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.webp'))]\n",
    "    print(f\"üîç Found {len(image_files)} images to classify in: {google_images_dir}\")\n",
    "    # Retrain folder base path\n",
    "    retrain_base = os.path.join(\n",
    "        os.path.dirname(google_images_dir),  # Goes up one level from image folder\n",
    "        'retrain'\n",
    "    )\n",
    "    os.makedirs(retrain_base, exist_ok=True)\n",
    "    # Ensure subfolders exist\n",
    "    for class_name in class_names:\n",
    "        os.makedirs(os.path.join(retrain_base, class_name), exist_ok=True)\n",
    "\n",
    "    for img_file in image_files:\n",
    "        img_path = os.path.join(google_images_dir, img_file)\n",
    "        # Load and preprocess image\n",
    "        img = image.load_img(img_path, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "        # Predict\n",
    "        predictions = model.predict(img_array, verbose=0)\n",
    "        predicted_class_index = np.argmax(predictions[0])\n",
    "        predicted_class = class_names[predicted_class_index]\n",
    "        confidence = np.max(predictions[0])\n",
    "\n",
    "        if confidence < confidence_threshold:\n",
    "            print(f\"\\n‚ö†Ô∏è  LOW CONFIDENCE: {img_file}\")\n",
    "            print(f\"Predicted: {predicted_class} ({confidence * 100:.2f}%)\")\n",
    "\n",
    "            # Ask doctor for correct label\n",
    "            doctor_input = input(\"Doctor input (oral_disorder / skin_diseases): \").strip().lower()\n",
    "            while doctor_input not in class_names:\n",
    "                print(\"‚ùå Invalid input. Please enter 'oral_disorder' or 'skin_diseases'.\")\n",
    "                doctor_input = input(\"Doctor input: \").strip().lower()\n",
    "            # Move image to retrain folder\n",
    "            dest_path = os.path.join(retrain_base, doctor_input, img_file)\n",
    "            shutil.move(img_path, dest_path)\n",
    "            print(f\"‚úÖ Moved to: retrain/{doctor_input}/{img_file}\")\n",
    "        else:\n",
    "            print(f\"{img_file}: ‚úÖ {predicted_class} ({confidence * 100:.2f}%)\")\n",
    "    print(\"\\nüì¶ Classification complete. Low-confidence images moved for retraining.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1526ed8f-7868-49fd-82f5-871d0ba659e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== MAIN EXECUTION ====================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Domain Classifier Training...\")\n",
    "    print(f\"Training samples: {len(os.listdir(os.path.join(train_dir, 'skin_diseases')))} skin + {len(os.listdir(os.path.join(train_dir, 'oral_disorder')))} oral\")\n",
    "    print(f\"Validation samples: {len(os.listdir(os.path.join(val_dir, 'skin_diseases')))} skin + {len(os.listdir(os.path.join(val_dir, 'oral_disorder')))} oral\")\n",
    "    \n",
    "    # Train the model\n",
    "    model, train_gen, val_gen, test_gen = train_domain_classifier()\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\nEvaluating on test set...\")\n",
    "    test_accuracy, y_true, y_pred = evaluate_model(model, test_gen)\n",
    "    \n",
    "    # Load best model for final evaluation\n",
    "    print(\"\\nLoading best model for final evaluation...\")\n",
    "    best_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "    final_accuracy, _, _ = evaluate_model(best_model, test_gen)\n",
    "    \n",
    "    print(f\"\\nüéØ Final Domain Classifier Performance: {final_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb119f96-8a35-454b-895d-9316fd7fbc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 12 images to classify in: /mnt/k/ml/clg_ml/imgs_from_google/domainClassifier/\n",
      "be_ke_le.jpeg: ‚úÖ skin_diseases (100.00%)\n",
      "be_ke_le2.jpg: ‚úÖ skin_diseases (100.00%)\n",
      "ecz.webp: ‚úÖ skin_diseases (98.70%)\n",
      "ecz2.jpg: ‚úÖ skin_diseases (99.31%)\n",
      "hypo.jpeg: ‚úÖ oral_disorder (100.00%)\n",
      "hypo2.jpg: ‚úÖ oral_disorder (100.00%)\n",
      "hypo3.jpg: ‚úÖ oral_disorder (99.90%)\n",
      "mo_ul.jpeg: ‚úÖ oral_disorder (100.00%)\n",
      "mo_ul2.jpg: ‚úÖ oral_disorder (99.99%)\n",
      "mo_ul3.jpg: ‚úÖ oral_disorder (99.97%)\n",
      "pso.webp: ‚úÖ skin_diseases (99.99%)\n",
      "pso2.jpg: ‚úÖ skin_diseases (100.00%)\n",
      "\n",
      "üì¶ Classification complete. Low-confidence images moved for retraining.\n"
     ]
    }
   ],
   "source": [
    "classify_google_images('domain_classifier_best.h5', '/mnt/k/ml/clg_ml/imgs_from_google/domainClassifier/', confidence_threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54eba81d-9e6d-4463-8c25-1febac4bc665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Feedback loop check: Found 0 images in retrain folder.\n",
      "‚è≥ Not enough data to retrain. Need 50, have 0.\n"
     ]
    }
   ],
   "source": [
    "feedback_loop_retraining(\n",
    "    retrain_dir=os.path.join(os.path.dirname(google_images_dir), 'retrain'),\n",
    "    model_path=MODEL_PATH,\n",
    "    min_images=50,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05f0cc-2fd1-4171-ab56-b9713be04149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cc432-8190-4a24-8eba-c8c5d2a30000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4b081-567f-4abd-9c86-a64ea7785e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87316d1-5a4b-4f19-8416-dae6e6e8b34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ca1040-c7b4-4f19-a032-2c31f9cebaa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc78a957-4088-445a-ab76-07e7bd5e7b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93925403-49e2-42ed-9b15-914d4c13db4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5293851-69f8-4cc9-a224-eeb4b17606f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e96989-585f-4e7b-bf29-cbecdd746cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e53b8c-5782-468f-94af-e397b345960f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794be30f-6fdb-4ac5-8476-1e509b359088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f303e2-d9c4-49d0-baf0-95fd45edeff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc01d80-9fe5-4e1f-b7cd-71b3a01afd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce1691-400b-4794-a638-814a93deba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71778682-ec33-4570-b502-86d5d224ddd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
